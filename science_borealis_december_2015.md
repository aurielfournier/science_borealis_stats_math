# evaluating risk : why bacon is not going to kill you
(not sold on this title, but its a title)
By: Andrew MacDonald and Auriel Fournier

Most of us hear statistics on a daily basis, be it a weather prediction (30% chance of rain) or a new study on the health risks of coffee or bacon (it really does cause cancer thsi time!). In both these cases we are provided with soem numbers, and those numbers are often surroudned by catchy writing that doesn't actually interpret the numbers as a statistic. 

Humans are pretty bad at evaluating risk as it is anyway, much less when we don't know how to interpret the data that is set before us. 

So lets start with something that is relatively low risk, the weather. You hear the forecast on the radio and it says there is a 30% chance of rain today. What does that actually mean, should you prepare for rain?  should you close your bedroom window? The answer to those last two questions is more objective, but what 30% chance means is that there is a 1 in 3 chance that at some point during the day it will rain. That does not mean it will rain 30% of the time. It could rain all day in fact and still meat the criteria of 30% chance. It could also not rain, at all, and the forecast is still accurate. But in an insance like possibly getting rained on this might not really be a high stakes moment. 

What if you are trying to understand the risks involved with consuming a certain kind of food, or the risks associated with a certain kind of medical treatment, these could be more more serious decisions and understanding the math is important. 

[bacon example here]

The World Health Organization (WHO) recently released a report that has been portrayed in some news stories as saying that bacon gives you cancer. Since bacon is loved by many people these headlines drew massive attention and discussion but when we dig deeper into the results, we realize three is mroe to the story then 'stop eating bacon to prevent cancer'.

(possibly link to Terry McGlyn's podcast that mentions the bacon stuff, they have a good discussion of the issue for folks who want to hear more about it)

[risk of flying vs driving]

Many people experience great anxiety about flying, some of this is related to the lack of control involved with flying, others because they are afraid that it is not safe. This is despite the fact that you are more likely to die driving a car within five minutes of your house then you are flying, and most people fly so infreuquently that their chance of dying while flying is essentially zero. Humans are bad at evaluating risk, and coverage by the media does not help since plane crashes are often news regionally if not nationally where as a car crash that kills the driver might not even make the newspaper. 

when evaluating how safe something is a few things needed to be considered. We need to consider the probability of a bad outcome (either injury, death, or otherwise) and then also consider how frequently we will be exposed to that risk. If you only fly one a year, your exposure to that risk is very low, making your risk of dying while flying lower then that of a person who flies for work every week. 

[why interpretation is important]

Often there is talk of statistics being a lot of hand waving and lies. While there are many examples of the mis-use of statistics when evaluating risk much of the spin comes in the evaluation of 'what is acceptable levels of risk' which is not a mathematical question. That is a human question, While mathematics and statistics can help us understand the risks associated with different decisions they cannot make those decisions for us, we have to decide what level of risk we are ok with. 30% chance of rain, sure, I'll risk it and not take my raincoat since the worst that can happen is getting wet. 30% chance of the surgery killing me, I'll think about it longer then I did the rain coat, thats for sure, since the consequences are greater. 

[correlation vs Causation]

Another issue that often results in misinterpreation of data or results is the confusion of correlation and causation. If two things are correlated they follow a pattern.

For instance as per capita ice cream consumption increases so does per capita rate of wearing shorts

While these two things may increase together that does not mean that eating ice cream makes you want to wear shorts, or vice versa (in this case the argument could probably be made that increasing temperatures in the summer could cause either of these).

There are many many variables that are correlated that does not mean they are actually causing the other one to change, this is one of teh big mistakes that is often made when interpreting data and we will cover it in more depth in a future post. 